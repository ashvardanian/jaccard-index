{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting pyarrow\n",
      "  Using cached pyarrow-15.0.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting usearch\n",
      "  Using cached usearch-2.9.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (26 kB)\n",
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting numpy<2,>=1.26.0 (from pandas)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tqdm (from usearch)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached pandas-2.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "Using cached pyarrow-15.0.2-cp312-cp312-manylinux_2_28_x86_64.whl (38.3 MB)\n",
      "Using cached usearch-2.9.2-cp312-cp312-manylinux_2_28_x86_64.whl (2.3 MB)\n",
      "Using cached faiss_cpu-1.8.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytz, tzdata, tqdm, six, numpy, usearch, python-dateutil, pyarrow, faiss-cpu, pandas\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2024.1\n",
      "    Uninstalling pytz-2024.1:\n",
      "      Successfully uninstalled pytz-2024.1\n",
      "  Attempting uninstall: tzdata\n",
      "    Found existing installation: tzdata 2024.1\n",
      "    Uninstalling tzdata-2024.1:\n",
      "      Successfully uninstalled tzdata-2024.1\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: usearch\n",
      "    Found existing installation: usearch 2.9.2\n",
      "    Uninstalling usearch-2.9.2:\n",
      "      Successfully uninstalled usearch-2.9.2\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 15.0.2\n",
      "    Uninstalling pyarrow-15.0.2:\n",
      "      Successfully uninstalled pyarrow-15.0.2\n",
      "  Attempting uninstall: faiss-cpu\n",
      "    Found existing installation: faiss-cpu 1.8.0\n",
      "    Uninstalling faiss-cpu-1.8.0:\n",
      "      Successfully uninstalled faiss-cpu-1.8.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.1\n",
      "    Uninstalling pandas-2.2.1:\n",
      "      Successfully uninstalled pandas-2.2.1\n",
      "Successfully installed faiss-cpu-1.8.0 numpy-1.26.4 pandas-2.2.1 pyarrow-15.0.2 python-dateutil-2.9.0.post0 pytz-2024.1 six-1.16.0 tqdm-4.66.2 tzdata-2024.1 usearch-2.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall pandas pyarrow usearch faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can potentially download all of 500 GB of content, but we don't need all of that. We don't need the original float-based embeddings. And we may not need all the languages at once, so let's start with just English, comparing Cohere and MixedBread embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 100,000\n"
     ]
    }
   ],
   "source": [
    "file_path = 'cohere/en-00000.parquet'\n",
    "df = pq.read_table(file_path)\n",
    "print(f\"rows: {len(df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarrow.FixedSizeBinaryScalar: b'\\xbeiOZ\\xcb\\xc6\\xf7\\x89=\\xe3]\\xfa\\xaf\\x1f\\x9d:^\\xf0[*\\xdb\\xd8k\\n\\xa8\\x16q; \\xa2\\xdc0v\\xa5|\\xa2.\\x80;\\xe0$\\xce\\x1d\\xa0\\xea\\x1d]\\x1dg\\x80?\\x14\\x90\\xa7\\x9e\\xdf\\xeav%\\xa5\\x06\\x96\\x87\\xb5j\\xb8@\\xed\\x878;\\x81\\x8e\\xae\\x11]\\xae3\\x10\\x19\\xb4\\xb9\\x9f/\\xe3\\xee\\x7f\\xdf&}\\x8c\\xe5$\\x03\\x89=*\\xdf\\x0c\\x92\\x88n\\xd4\\xd8L\\xf1\\xf9\\xd8\\x81^\\xc1~\\x9ed\\xd8QK\\xfe\\xee\\x92\\xf8uE\\xe8\\x00\\xdf\\xf46'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emb'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_array(x):\n",
    "    binary_data = x.as_buffer()\n",
    "    array_uint8 = np.frombuffer(binary_data, dtype=np.uint8)\n",
    "    return array_uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vstack_files(dir):\n",
    "    embeddings = []\n",
    "    filenames = sorted(os.listdir(dir))\n",
    "\n",
    "    # Iterate through all the Parquet files in the directory\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".parquet\"):\n",
    "            file_path = os.path.join(dir, filename)\n",
    "            # Read the table from the Parquet file\n",
    "            df = pq.read_table(file_path)\n",
    "            df_embeddings = [to_array(x) for x in df['emb']]\n",
    "            # print(f\"Read {len(df_embeddings):,} embeddings from {filename} with shape {df_embeddings[0].shape}\")\n",
    "            embeddings.extend(df_embeddings)\n",
    "    \n",
    "    embeddings = np.vstack(embeddings)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41488110, 128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = vstack_files('cohere')\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's benchmark exact search on a small subset of the data with FAISS and USearch, [like in the Sentence Transformers benchmark](https://github.com/UKPLab/sentence-transformers/pull/2549)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_force_limit_vectors = 100_000\n",
    "brute_force_limit_queries = 1_000\n",
    "brute_force_limit_matches = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's shuffle the data a bit, so the results are not biased by the order of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_force_vectors_indices = np.random.choice(embeddings.shape[0], size=brute_force_limit_vectors, replace=False)\n",
    "brute_force_vectors = embeddings[brute_force_vectors_indices]\n",
    "brute_force_queries_indices = np.random.choice(brute_force_limit_vectors, size=brute_force_limit_queries, replace=False)\n",
    "brute_force_queries = embeddings[brute_force_queries_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Search\n",
    "\n",
    "### FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 1024  # This is the bit dimension, change according to your data\n",
    "index = faiss.IndexBinaryFlat(dim)\n",
    "index.add(brute_force_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "index = faiss.IndexBinaryFlat(dim)\n",
    "index.add(brute_force_vectors)\n",
    "faiss_distances, faiss_indices = index.search(brute_force_queries, brute_force_limit_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from usearch.index import MetricKind, search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "795 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "usearch_results = search(brute_force_vectors, brute_force_queries, brute_force_limit_matches, MetricKind.Hamming, exact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate Search\n",
    "\n",
    "### USearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'avx2'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from usearch.index import Index, MetricKind\n",
    "index = Index(ndim=1024, metric=MetricKind.Hamming)\n",
    "index.hardware_acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add: 100%|██████████| 41488110/41488110 [05:33<00:00, 124240.87vector/s]\n"
     ]
    }
   ],
   "source": [
    "_ = index.add(None, embeddings, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Search: 100%|██████████| 41488110/41488110 [02:12<00:00, 312524.52vector/s]\n"
     ]
    }
   ],
   "source": [
    "matches = index.search(embeddings, 10, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usearch.Index\n",
       "- config\n",
       "-- data type: ScalarKind.B1\n",
       "-- dimensions: 1024\n",
       "-- metric: MetricKind.Hamming\n",
       "-- multi: False\n",
       "-- connectivity: 16\n",
       "-- expansion on addition:128 candidates\n",
       "-- expansion on search: 64 candidates\n",
       "- binary\n",
       "-- uses OpenMP: 0\n",
       "-- uses SimSIMD: 1\n",
       "-- supports half-precision: 1\n",
       "-- uses hardware acceleration: avx2\n",
       "- state\n",
       "-- size: 41,488,110 vectors\n",
       "-- memory usage: 17,704,181,120 bytes\n",
       "-- max level: 4\n",
       "--- 0. 41,488,110 nodes\n",
       "--- 1. 2,576,252 nodes\n",
       "--- 2. 164,927 nodes\n",
       "--- 3. 11,904 nodes\n",
       "--- 4. 1,344 nodes"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SearchStats(index_size=41488110, count_queries=41488110, count_matches=40068659, visited_members=3677721960, computed_distances=76061010852)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from usearch.eval import SearchStats\n",
    "\n",
    "keys = np.arange(embeddings.shape[0])\n",
    "count_matches: int = matches.count_matches(keys)\n",
    "stats = SearchStats(\n",
    "    index_size=len(index),\n",
    "    count_queries=len(keys),\n",
    "    count_matches=count_matches,\n",
    "    visited_members=matches.visited_members,\n",
    "    computed_distances=matches.computed_distances,\n",
    ")\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.965786559088857"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mean_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999558109371663"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.mean_efficiency"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
